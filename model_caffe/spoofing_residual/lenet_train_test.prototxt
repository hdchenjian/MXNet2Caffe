name: "LeNet"

layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape: { dim: 1 dim: 3 dim: 112 dim: 96 }
  }
}

layer {
	bottom: "data"
	top: "conv0"
	name: "conv0"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "conv0"
  top: "bn0"
  name: "bn0"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "bn0"
  top: "bn0"
  name: "bn0_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "bn0"
  top: "relu0"
  name: "relu0"
  type: "PReLU"
}

layer {
  bottom: "relu0"
  top: "stage1_unit1_bn1"
  name: "stage1_unit1_bn1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "stage1_unit1_bn1"
  top: "stage1_unit1_bn1"
  name: "stage1_unit1_bn1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
	bottom: "stage1_unit1_bn1"
	top: "stage1_unit1_conv1"
	name: "stage1_unit1_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage1_unit1_conv1"
  top: "stage1_unit1_bn2"
  name: "stage1_unit1_bn2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "stage1_unit1_bn2"
  top: "stage1_unit1_bn2"
  name: "stage1_unit1_bn2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage1_unit1_bn2"
  top: "stage1_unit1_relu1"
  name: "stage1_unit1_relu1"
  type: "PReLU"
}

layer {
	bottom: "stage1_unit1_relu1"
	top: "stage1_unit1_conv2"
	name: "stage1_unit1_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 3
		pad: 1
		stride: 2
		bias_term: false
	}
}

layer {
  bottom: "stage1_unit1_conv2"
  top: "stage1_unit1_bn3"
  name: "stage1_unit1_bn3"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "stage1_unit1_bn3"
  top: "stage1_unit1_bn3"
  name: "stage1_unit1_bn3_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
	bottom: "relu0"
	top: "stage1_unit1_conv1sc"
	name: "stage1_unit1_conv1sc"
	type: "Convolution"
	convolution_param {
		num_output: 64
		kernel_size: 1
		stride: 2
		bias_term: false
	}
}

layer {
  bottom: "stage1_unit1_conv1sc"
  top: "stage1_unit1_sc"
  name: "stage1_unit1_sc"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "stage1_unit1_sc"
  top: "stage1_unit1_sc"
  name: "stage1_unit1_sc_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  name: "_plus0"
  type: "Eltwise"
  bottom: "stage1_unit1_bn3"
  bottom: "stage1_unit1_sc"
  top: "_plus0"
  eltwise_param { operation: SUM }
}



layer {
  bottom: "_plus0"
  top: "stage2_unit1_bn1"
  name: "stage2_unit1_bn1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "stage2_unit1_bn1"
  top: "stage2_unit1_bn1"
  name: "stage2_unit1_bn1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}



layer {
	bottom: "stage2_unit1_bn1"
	top: "stage2_unit1_conv1"
	name: "stage2_unit1_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage2_unit1_conv1"
  top: "stage2_unit1_bn2"
  name: "stage2_unit1_bn2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "stage2_unit1_bn2"
  top: "stage2_unit1_bn2"
  name: "stage2_unit1_bn2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage2_unit1_bn2"
  top: "stage2_unit1_relu1"
  name: "stage2_unit1_relu1"
  type: "PReLU"
}

layer {
	bottom: "stage2_unit1_relu1"
	top: "stage2_unit1_conv2"
	name: "stage2_unit1_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 3
		pad: 1
		stride: 2
		bias_term: false
	}
}

layer {
  bottom: "stage2_unit1_conv2"
  top: "stage2_unit1_bn3"
  name: "stage2_unit1_bn3"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "stage2_unit1_bn3"
  top: "stage2_unit1_bn3"
  name: "stage2_unit1_bn3_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
	bottom: "_plus0"
	top: "stage2_unit1_conv1sc"
	name: "stage2_unit1_conv1sc"
	type: "Convolution"
	convolution_param {
		num_output: 128
		kernel_size: 1
		stride: 2
		bias_term: false
	}
}

layer {
  bottom: "stage2_unit1_conv1sc"
  top: "stage2_unit1_sc"
  name: "stage2_unit1_sc"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "stage2_unit1_sc"
  top: "stage2_unit1_sc"
  name: "stage2_unit1_sc_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  name: "_plus3"
  type: "Eltwise"
  bottom: "stage2_unit1_bn3"
  bottom: "stage2_unit1_sc"
  top: "_plus3"
  eltwise_param { operation: SUM }
}





layer {
  bottom: "_plus3"
  top: "stage3_unit1_bn1"
  name: "stage3_unit1_bn1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "stage3_unit1_bn1"
  top: "stage3_unit1_bn1"
  name: "stage3_unit1_bn1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}


layer {
	bottom: "stage3_unit1_bn1"
	top: "stage3_unit1_conv1"
	name: "stage3_unit1_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage3_unit1_conv1"
  top: "stage3_unit1_bn2"
  name: "stage3_unit1_bn2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "stage3_unit1_bn2"
  top: "stage3_unit1_bn2"
  name: "stage3_unit1_bn2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage3_unit1_bn2"
  top: "stage3_unit1_relu1"
  name: "stage3_unit1_relu1"
  type: "PReLU"
}

layer {
	bottom: "stage3_unit1_relu1"
	top: "stage3_unit1_conv2"
	name: "stage3_unit1_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 3
		pad: 1
		stride: 2
		bias_term: false
	}
}

layer {
  bottom: "stage3_unit1_conv2"
  top: "stage3_unit1_bn3"
  name: "stage3_unit1_bn3"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "stage3_unit1_bn3"
  top: "stage3_unit1_bn3"
  name: "stage3_unit1_bn3_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
	bottom: "_plus3"
	top: "stage3_unit1_conv1sc"
	name: "stage3_unit1_conv1sc"
	type: "Convolution"
	convolution_param {
		num_output: 256
		kernel_size: 1
		stride: 2
		bias_term: false
	}
}

layer {
  bottom: "stage3_unit1_conv1sc"
  top: "stage3_unit1_sc"
  name: "stage3_unit1_sc"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "stage3_unit1_sc"
  top: "stage3_unit1_sc"
  name: "stage3_unit1_sc_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  name: "_plus7"
  type: "Eltwise"
  bottom: "stage3_unit1_bn3"
  bottom: "stage3_unit1_sc"
  top: "_plus7"
  eltwise_param { operation: SUM }
}


# 6x7

layer {
  bottom: "_plus7"
  top: "stage4_unit1_bn1"
  name: "stage4_unit1_bn1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "stage4_unit1_bn1"
  top: "stage4_unit1_bn1"
  name: "stage4_unit1_bn1_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
	bottom: "stage4_unit1_bn1"
	top: "stage4_unit1_conv1"
	name: "stage4_unit1_conv1"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 1
		bias_term: false
	}
}

layer {
  bottom: "stage4_unit1_conv1"
  top: "stage4_unit1_bn2"
  name: "stage4_unit1_bn2"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "stage4_unit1_bn2"
  top: "stage4_unit1_bn2"
  name: "stage4_unit1_bn2_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  bottom: "stage4_unit1_bn2"
  top: "stage4_unit1_relu1"
  name: "stage4_unit1_relu1"
  type: "PReLU"
}

layer {
	bottom: "stage4_unit1_relu1"
	top: "stage4_unit1_conv2"
	name: "stage4_unit1_conv2"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 3
		pad: 1
		stride: 2
		bias_term: false
	}
}

layer {
  bottom: "stage4_unit1_conv2"
  top: "stage4_unit1_bn3"
  name: "stage4_unit1_bn3"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "stage4_unit1_bn3"
  top: "stage4_unit1_bn3"
  name: "stage4_unit1_bn3_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
	bottom: "_plus7"
	top: "stage4_unit1_conv1sc"
	name: "stage4_unit1_conv1sc"
	type: "Convolution"
	convolution_param {
		num_output: 512
		kernel_size: 1
		stride: 2
		bias_term: false
	}
}

layer {
  bottom: "stage4_unit1_conv1sc"
  top: "stage4_unit1_sc"
  name: "stage4_unit1_sc"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
    eps: 2e-05
  }
}
layer {
  bottom: "stage4_unit1_sc"
  top: "stage4_unit1_sc"
  name: "stage4_unit1_sc_scale"
  type: "Scale"
  scale_param { bias_term: true }
}

layer {
  name: "_plus13"
  type: "Eltwise"
  bottom: "stage4_unit1_bn3"
  bottom: "stage4_unit1_sc"
  top: "_plus13"
  eltwise_param { operation: SUM }
}

layer {
  name: "pool1"
  type: "Pooling"
  bottom: "_plus13"
  top: "pool1"
  pooling_param {
    pool: AVE
    kernel_h: 7
    kernel_w: 6
    stride: 1
  }
}

layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "fc1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
